<html>

<head>
<title>
Publications of year 2018</title>
<META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<META name="keywords" lang="en" content="bibtex2html, bibliography, article, report">
<META name="GENERATOR" content="bibtex2html 1.01">
</head>
<body bgcolor="#ffffff" link="blue" alink="blue" vlink="blue">


<br />
<a href="../index.html"><strong> BACK TO INDEX </strong></a>
<br /><br />


<table width="100%">
<tr><td height="50" bgcolor="#669999" align="center">
<strong><font size=6 color="#ffffff" face="times">
Publications of year 2018
</font></strong>
</td></tr>
</table>


<table width="100%">
<tr><td height="35"  align="center" valign="center" bgcolor="#badfe1">
<strong><font size=4 face="times">
Conference articles
</font></strong>
</td></tr>
</table>


<ol>

<li>
<a name="Bicici:RTM:WMT2018"></a><a href="../Author/BICICI-E.html">Ergun Biçici</a>.
<strong>RTM results for Predicting Translation Performance</strong>.
In <em>Proc. of the Third Conf. on Machine Translation (WMT18)</em>,
Brussels, Belgium,
pages 765-769,
10 2018.
Keyword(s): <a href="../Keyword/MACHINE-TRANSLATION.html">Machine Translation</a>,
<a href="../Keyword/MACHINE-LEARNING.html">Machine Learning</a>,
<a href="../Keyword/PERFORMANCE-PREDICTION.html">Performance Prediction</a>.
<center>
<table border=1 align=center width=80%>
<tr>
Abstract: <td>
With improved prediction combination using weights based on their training performance and stacking and multilayer perceptrons to build deeper prediction models, RTMs become the 3rd system in general at the sentence-level prediction of translation scores and achieve the lowest RMSE in English to German NMT QET results. For the document-level task, we compare document-level RTM models with sentence-level RTM models obtained with the concatenation of document sentences and obtain similar results.</td>

</tr></table></center>
<br /><pre>
@InProceedings{Bicici:RTM:WMT2018,
author = {Ergun Bi\c{c}ici},
title = {{RTM} results for Predicting Translation Performance},
booktitle = {Proc. of the {T}hird {C}onf. on {M}achine {T}ranslation ({WMT18})},
month = {10},
year = {2018},
pages = {765--769},
address = {Brussels, Belgium},
keywords = "Machine Translation, Machine Learning, Performance Prediction",
abstract = {With improved prediction combination using weights based on their training performance and stacking and multilayer perceptrons to build deeper prediction models, RTMs become the 3rd system in general at the sentence-level prediction of translation scores and achieve the lowest RMSE in English to German NMT QET results. For the document-level task, we compare document-level RTM models with sentence-level RTM models obtained with the concatenation of document sentences and obtain similar results.},

}
</pre>

</li>
<br /><br />


<li>
<a name="Bicici:parfda:WMT2018"></a><a href="../Author/BICICI-E.html">Ergun Biçici</a>.
<strong>Robust parfda Statistical Machine Translation Results</strong>.
In <em>Proc. of the Third Conf. on Machine Translation (WMT18)</em>,
Brussels, Belgium,
pages 345-354,
10 2018.
Keyword(s): <a href="../Keyword/MACHINE-TRANSLATION.html">Machine Translation</a>.
<center>
<table border=1 align=center width=80%>
<tr>
Abstract: <td>
We build parallel feature decay algorithms (	exttt{parfda}) Moses statistical machine translation (SMT) models for language pairs in the translation task. 	exttt{parfda} obtains results close to the top constrained phrase-based SMT with an average of $2.252$ BLEU points difference on WMT 2017 datasets using significantly less computation for building SMT systems than that would be spent using all available corpora. We obtain BLEU upper bounds based on target coverage to identify which systems used additional data. We use PRO for tuning to decrease fluctuations in the results and post-process translation outputs to decrease translation errors due to the casing of words. $F_1$ scores on the key phrases of the English to Turkish testsuite that we prepared reveal that 	exttt{parfda} achieves $2nd$ best results. Truecasing translations before scoring obtained the best results overall.</td>

</tr></table></center>
<br /><pre>
@InProceedings{Bicici:parfda:WMT2018,
author = {Ergun Bi\c{c}ici},
title = {Robust parfda Statistical Machine Translation Results},
booktitle = {Proc. of the {T}hird {C}onf. on {M}achine {T}ranslation ({WMT18})},
month = {10},
year = {2018},
pages = {345--354},
address = {Brussels, Belgium},
keywords = {Machine Translation},
abstract = {We build parallel feature decay algorithms (	exttt{parfda}) Moses statistical machine translation (SMT) models for language pairs in the translation task. 	exttt{parfda} obtains results close to the top constrained phrase-based SMT with an average of $2.252$ BLEU points difference on WMT 2017 datasets using significantly less computation for building SMT systems than that would be spent using all available corpora. We obtain BLEU upper bounds based on target coverage to identify which systems used additional data. We use PRO for tuning to decrease fluctuations in the results and post-process translation outputs to decrease translation errors due to the casing of words. $F_1$ scores on the key phrases of the English to Turkish testsuite that we prepared reveal that 	exttt{parfda} achieves $2nd$ best results. Truecasing translations before scoring obtained the best results overall.},

}
</pre>

</li>
<br /><br />


</ol>

<br />
<a href="../index.html"><strong> BACK TO INDEX </strong></a>
<br /><br />


<br /><hr size="2" width="100%"><br />

<u><strong>Disclaimer:</strong></u><br /><br />
<p><em>
This material is presented to ensure timely dissemination of
scholarly and technical work. Copyright and all rights therein
are retained by authors or by other copyright holders.
All person copying this information are expected to adhere to
the terms and constraints invoked by each author's copyright.
In most cases, these works may not be reposted
without the explicit permission of the copyright holder.

</em></p>
<p><em>
Les documents contenus dans ces répertoires sont rendus disponibles
par les auteurs qui y ont contribué en vue d'assurer la diffusion
à temps de travaux savants et techniques sur une base non-commerciale.
Les droits de copie et autres droits sont gardés par les auteurs
et par les détenteurs du copyright, en dépit du fait qu'ils présentent
ici leurs travaux sous forme électronique. Les personnes copiant ces
informations doivent adhérer aux termes et contraintes couverts par
le copyright de chaque auteur. Ces travaux ne peuvent pas être
rendus disponibles ailleurs sans la permission explicite du détenteur
du copyright.

</em></p>

<br /><hr size="2" width="100%"><br />

Last modified: Mon Jul 29 10:22:15 2019

<br />Author: ebicici.

<br /><hr size="2" width="100%"><br />

<p>This document was translated from BibT<sub>E</sub>X by
<a href="http://www-sop.inria.fr/epidaure/personnel/malandain/codes/bibtex2html.html"><em>bibtex2html</em></a>
</p>


</body>


</html>
