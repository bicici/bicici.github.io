<html>

<head>
<title>
Publications of year 2016</title>
<META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<META name="keywords" lang="en" content="bibtex2html, bibliography, article, report">
<META name="GENERATOR" content="bibtex2html 1.01">
</head>
<body bgcolor="#ffffff" link="blue" alink="blue" vlink="blue">


<br />
<a href="../index.html"><strong> BACK TO INDEX </strong></a>
<br /><br />


<table width="100%">
<tr><td height="50" bgcolor="#669999" align="center">
<strong><font size=6 color="#ffffff" face="times">
Publications of year 2016
</font></strong>
</td></tr>
</table>


<table width="100%">
<tr><td height="35"  align="center" valign="center" bgcolor="#badfe1">
<strong><font size=4 face="times">
Articles in journal, book chapters
</font></strong>
</td></tr>
</table>


<ol>

<li>
<a name="Bicici:RTMPPP:PBML2016"></a><a href="../Author/BICICI-E.html">Ergun Biçici</a>.
<strong>Predicting the Performance of Parsing with Referential Translation Machines</strong>.
<em>The Prague Bulletin of Mathematical Linguistics</em>,
106:31-44,
2016.
<strong>ISSN:</strong> 1804-0462.
[doi:<a href="http://dx.doi.org/10.1515/pralin-2016-0010">10.1515/pralin-2016-0010</a>]
Keyword(s): <a href="../Keyword/REFERENTIAL-TRANSLATION-MACHINES.html">referential translation machines</a>,
<a href="../Keyword/MACHINE-TRANSLATION.html">machine translation</a>,
<a href="../Keyword/PARSING.html">parsing</a>.
<center>
<table border=1 align=center width=80%>
<tr>
Abstract: <td>
Referential translation machine (RTM) is a prediction engine used for predicting the performance of natural language processing tasks including parsing, machine translation, and semantic similarity pioneering language, task, and domain independence. RTM results for predicting the performance of parsing (PPP) in out-of-domain or in-domain settings with different training sets and types of features present results independent of language or parser. RTM PPP models can be used without parsing using only text input and without any parser or language dependent information. Our results detail prediction performance, top selected features, and lower bound on the prediction error of PPP.</td>

</tr></table></center>
<br /><pre>
@article{Bicici:RTMPPP:PBML2016,
author = {Ergun Bi\c{c}ici},
title = {Predicting the Performance of Parsing with Referential Translation Machines},
journal = {The Prague Bulletin of Mathematical Linguistics},
year = {2016},
volume = {106},
pages = {31--44},
issn = {1804-0462},
doi = {10.1515/pralin-2016-0010},
keywords = {referential translation machines, machine translation, parsing},
abstract = {Referential translation machine (RTM) is a prediction engine used for predicting the performance of natural language processing tasks including parsing, machine translation, and semantic similarity pioneering language, task, and domain independence. RTM results for predicting the performance of parsing (PPP) in out-of-domain or in-domain settings with different training sets and types of features present results independent of language or parser. RTM PPP models can be used without parsing using only text input and without any parser or language dependent information. Our results detail prediction performance, top selected features, and lower bound on the prediction error of PPP.},

}
</pre>

</li>
<br /><br />


</ol>

<table width="100%">
<tr><td height="35"  align="center" valign="center" bgcolor="#badfe1">
<strong><font size=4 face="times">
Conference articles
</font></strong>
</td></tr>
</table>


<ol>

<li>
<a name="Bicici:ParFDA:WMT2016"></a><a href="../Author/BICICI-E.html">Ergun Biçici</a>.
<strong>ParFDA for Instance Selection for Statistical Machine Translation</strong>.
In <em>Proc. of the First Conference on Statistical Machine Translation (WMT16)</em>,
Berlin, Germany,
8 2016.
Association for Computational Linguistics.
[<a href="http://aclanthology.info/papers/parfda-for-instance-selection-for-statistical-machine-translation">WWW</a>]
[<a href="http://bicici.github.com/publications/2016/ParFDA_WMT.pdf">PDF</a>]
Keyword(s): <a href="../Keyword/MACHINE-TRANSLATION.html">Machine Translation</a>,
<a href="../Keyword/MACHINE-LEARNING.html">Machine Learning</a>,
<a href="../Keyword/LANGUAGE-MODELING.html">Language Modeling</a>.
<center>
<table border=1 align=center width=80%>
<tr>
Abstract: <td>
We build parallel feature decay algorithms (ParFDA) Moses statistical machine translation (SMT) systems for all language pairs in the translation task at the first conference on statistical machine translation~\cite{WMT2016} (WMT16). ParFDA obtains results close to the top constrained phrase-based SMT with an average of $2.52$ BLEU points difference using significantly less computation for building SMT systems than the computation that would be spent using all available corpora. We obtain BLEU bounds based on target coverage and show that ParFDA results can be improved by $12.6$ BLEU points on average. Similar bounds show that top constrained SMT results at WMT16 can be improved by $8$ BLEU points on average while German to English and Romanian to English translations results are already close to the bounds.</td>

</tr></table></center>
<br /><pre>
@InProceedings{Bicici:ParFDA:WMT2016,
author = {Ergun Bi\c{c}ici},
title = {{ParFDA} for Instance Selection for Statistical Machine Translation},
booktitle = {Proc. of the {F}irst {C}onference on {S}tatistical {M}achine {T}ranslation ({WMT16})},
month = {8},
year = {2016},
address = {Berlin, Germany},
publisher = {Association for Computational Linguistics},
url = {http://aclanthology.info/papers/parfda-for-instance-selection-for-statistical-machine-translation},
pdf = {http://bicici.github.com/publications/2016/ParFDA_WMT.pdf},
keywords = "Machine Translation, Machine Learning, Language Modeling",
abstract = {We build parallel feature decay algorithms (ParFDA) Moses statistical machine translation (SMT) systems for all language pairs in the translation task at the first conference on statistical machine translation~\cite{WMT2016} (WMT16). ParFDA obtains results close to the top constrained phrase-based SMT with an average of $2.52$ BLEU points difference using significantly less computation for building SMT systems than the computation that would be spent using all available corpora. We obtain BLEU bounds based on target coverage and show that ParFDA results can be improved by $12.6$ BLEU points on average. Similar bounds show that top constrained SMT results at WMT16 can be improved by $8$ BLEU points on average while German to English and Romanian to English translations results are already close to the bounds.},

}
</pre>

</li>
<br /><br />


<li>
<a name="Bicici:RTM:SEMEVAL2016"></a><a href="../Author/BICICI-E.html">Ergun Biçici</a>.
<strong>RTM at SemEval-2016 Task 1: Predicting Semantic Similarity with Referential Translation Machines and Related Statistics</strong>.
In <em>SemEval-2016: Semantic Evaluation Exercises - International Workshop on Semantic Evaluation</em>,
San Diego, CA, USA,
6 2016.
[<a href="http://aclanthology.info/papers/rtm-at-semeval-2016-task-1-predicting-semantic-similarity-with-referential-translation-machines-and-related-statistics">WWW</a>]
Keyword(s): <a href="../Keyword/MACHINE-TRANSLATION.html">Machine Translation</a>,
<a href="../Keyword/MACHINE-LEARNING.html">Machine Learning</a>,
<a href="../Keyword/PERFORMANCE-PREDICTION.html">Performance Prediction</a>,
<a href="../Keyword/SEMANTIC-SIMILARITY.html">Semantic Similarity</a>.
<center>
<table border=1 align=center width=80%>
<tr>
Abstract: <td>
We use referential translation machines (RTMs) for predicting the semantic similarity of text in both STS Core and Cross-lingual STS. RTMs pioneer a language independent approach to all similarity tasks and remove the need to access any task or domain specific information or resource. RTMs become 14th out of 26 submissions in Cross-lingual STS. We also present rankings of various prediction tasks using the performance of RTM in terms of MRAER, a normalized relative absolute error metric.</td>

</tr></table></center>
<br /><pre>
@InProceedings{Bicici:RTM:SEMEVAL2016,
author = {Ergun Bi\c{c}ici},
title = {{RTM} at {SemEval-2016} Task 1: Predicting Semantic Similarity with Referential Translation Machines and Related Statistics},
booktitle = {{SemEval-2016}: Semantic Evaluation Exercises - International Workshop on Semantic Evaluation},
month = {6},
year = {2016},
address = {San Diego, CA, USA},
url = {http://aclanthology.info/papers/rtm-at-semeval-2016-task-1-predicting-semantic-similarity-with-referential-translation-machines-and-related-statistics},
abstract = {We use referential translation machines (RTMs) for predicting the semantic similarity of text in both STS Core and Cross-lingual STS. RTMs pioneer a language independent approach to all similarity tasks and remove the need to access any task or domain specific information or resource. RTMs become 14th out of 26 submissions in Cross-lingual STS. We also present rankings of various prediction tasks using the performance of RTM in terms of MRAER, a normalized relative absolute error metric.},
keywords = "Machine Translation, Machine Learning, Performance Prediction, Semantic Similarity",

}
</pre>

</li>
<br /><br />


<li>
<a name="Bicici:RTM:WMT2016"></a><a href="../Author/BICICI-E.html">Ergun Biçici</a>.
<strong>Referential Translation Machines for Predicting Translation Quality and Related Statistics</strong>.
In <em>Proc. of the First Conference on Statistical Machine Translation (WMT16)</em>,
Berlin, Germany,
8 2016.
Association for Computational Linguistics.
[<a href="http://aclanthology.info/papers/referential-translation-machines-for-predicting-translation-performance">WWW</a>]
Keyword(s): <a href="../Keyword/MACHINE-TRANSLATION.html">Machine Translation</a>,
<a href="../Keyword/MACHINE-LEARNING.html">Machine Learning</a>,
<a href="../Keyword/PERFORMANCE-PREDICTION.html">Performance Prediction</a>.
<center>
<table border=1 align=center width=80%>
<tr>
Abstract: <td>
Referential translation machines (RTMs) pioneer a language independent approach for predicting translation performance and to all similarity tasks with top performance in both bilingual and monolingual settings and remove the need to access any task or domain specific information or resource. RTMs achieve to become $1$st in document-level, $4$th system at sentence-level according to mean absolute error, and $4$th in phrase-level prediction of translation quality in quality estimation task.</td>

</tr></table></center>
<br /><pre>
@InProceedings{Bicici:RTM:WMT2016,
author = {Ergun Bi\c{c}ici},
title = {Referential Translation Machines for Predicting Translation Quality and Related Statistics},
booktitle = {Proc. of the {F}irst {C}onference on {S}tatistical {M}achine {T}ranslation ({WMT16})},
month = {8},
year = {2016},
address = {Berlin, Germany},
publisher = {Association for Computational Linguistics},
url = {http://aclanthology.info/papers/referential-translation-machines-for-predicting-translation-performance},
keywords = "Machine Translation, Machine Learning, Performance Prediction",
abstract = {Referential translation machines (RTMs) pioneer a language independent approach for predicting translation performance and to all similarity tasks with top performance in both bilingual and monolingual settings and remove the need to access any task or domain specific information or resource. RTMs achieve to become $1$st in document-level, $4$th system at sentence-level according to mean absolute error, and $4$th in phrase-level prediction of translation quality in quality estimation task.},

}
</pre>

</li>
<br /><br />


</ol>

<br />
<a href="../index.html"><strong> BACK TO INDEX </strong></a>
<br /><br />


<br /><hr size="2" width="100%"><br />

<u><strong>Disclaimer:</strong></u><br /><br />
<p><em>
This material is presented to ensure timely dissemination of
scholarly and technical work. Copyright and all rights therein
are retained by authors or by other copyright holders.
All person copying this information are expected to adhere to
the terms and constraints invoked by each author's copyright.
In most cases, these works may not be reposted
without the explicit permission of the copyright holder.

</em></p>
<p><em>
Les documents contenus dans ces répertoires sont rendus disponibles
par les auteurs qui y ont contribué en vue d'assurer la diffusion
à temps de travaux savants et techniques sur une base non-commerciale.
Les droits de copie et autres droits sont gardés par les auteurs
et par les détenteurs du copyright, en dépit du fait qu'ils présentent
ici leurs travaux sous forme électronique. Les personnes copiant ces
informations doivent adhérer aux termes et contraintes couverts par
le copyright de chaque auteur. Ces travaux ne peuvent pas être
rendus disponibles ailleurs sans la permission explicite du détenteur
du copyright.

</em></p>

<br /><hr size="2" width="100%"><br />

Last modified: Sat Jun  3 00:08:21 2017

<br />Author: ebicici.

<br /><hr size="2" width="100%"><br />

<p>This document was translated from BibT<sub>E</sub>X by
<a href="http://www-sop.inria.fr/epidaure/personnel/malandain/codes/bibtex2html.html"><em>bibtex2html</em></a>
</p>


</body>


</html>
